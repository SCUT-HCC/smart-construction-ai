# 嵌入模型 + Reranker 综合评测报告

> **评测日期**: 2026-02-25
> **数据集**: 100 组 query-passage 对（含 4 条 hard negative），全量 692 条知识片段
> **硬件**: RTX 4090 (24GB VRAM), i9-13900K, 64GB RAM
> **环境**: Python 3.10, sentence-transformers, transformers (FP16)

---

## 一、嵌入模型综合排名

评测 4 个嵌入模型（Qwen3-Embedding-8B 因 OOM 无法评测，需 >16GB 显存）。

| # | 模型 | 维度 | MRR@3 | Hit@1 | Hit@3 | Hit@10 | 区分度 | 延迟(ms) | batch(s) | 显存(MB) |
|---|------|------|-------|-------|-------|--------|--------|---------|---------|---------|
| 1 | Qwen3-Embedding-4B | 2560 | **0.8917** | 85.0% | 94.0% | 98.0% | 0.4146 | 15.9 | 21.5 | 10269 |
| 2 | Qwen3-Embedding-0.6B | 1024 | **0.8600** | 82.0% | 91.0% | 94.0% | 0.4083 | 12.4 | 8.2 | 5557 |
| 3 | bge-m3 | 1024 | 0.7500 | 69.0% | 83.0% | 95.0% | 0.2477 | 6.6 | 18.2 | 18562 |
| 4 | bge-large-zh-v1.5 | 1024 | 0.6867 | 64.0% | 75.0% | 90.0% | 0.2363 | 6.6 | 3.7 | 2019 |

**关键发现**：
- Qwen3 系列在领域中文语义理解上显著优于 BGE 系列（MRR@3 高 14~21 个百分点）
- Qwen3-0.6B 以仅 5.6GB 显存达到 0.86 MRR@3，性价比极高
- bge-m3 显存占用 18.5GB 异常偏高（FP32 权重），且区分度仅 0.248

### 1.1 长文本衰减分析

数据集片段长度分布：<512 字 69 条 | 512-1024 字 18 条 | >1024 字 13 条

| 片段长度 | Qwen3-4B | Qwen3-0.6B | bge-m3 | bge-large-zh |
|---------|----------|------------|--------|-------------|
| <512 MRR@3 | **0.964** | 0.937 | 0.821 | 0.785 |
| <512 Hit@3 | **98.6%** | 97.1% | 87.0% | 84.1% |
| 512-1024 MRR@3 | **0.806** | 0.741 | 0.657 | 0.509 |
| 512-1024 Hit@3 | **88.9%** | 83.3% | 77.8% | 61.1% |
| >1024 MRR@3 | **0.628** | 0.615 | 0.500 | 0.410 |
| >1024 Hit@3 | **76.9%** | 69.2% | 69.2% | 46.2% |

**衰减趋势**：所有模型在 >1024 字片段上 MRR@3 下降 25~38 个百分点。建议对超长片段生成摘要增强向量。

### 1.2 按章节细粒度分析（对应 8 Collection 检索质量）

| 章节 | 样本数 | 对应 Collection | Qwen3-4B | Qwen3-0.6B | bge-m3 | bge-large-zh |
|------|--------|----------------|----------|------------|--------|-------------|
| 一、编制依据 | 5 | ch01_basis | **1.000** | 0.900 | 0.600 | 0.567 |
| 二、工程概况 | 3 | — (用户输入) | 0.778 | **0.833** | 0.778 | 0.667 |
| 三、施工组织 | 3 | templates | **1.000** | 0.667 | 0.500 | 0.333 |
| 四、施工安排 | 4 | ch06_methods | 0.750 | 0.750 | 0.625 | **0.750** |
| 五、施工准备 | 8 | equipment+templates | **1.000** | **1.000** | 0.938 | 0.854 |
| 六、施工方法 | 30 | ch06_methods | **0.928** | 0.861 | 0.861 | 0.717 |
| 七、质量管理 | 15 | ch07_quality | **0.867** | **0.867** | 0.667 | 0.733 |
| 八、安全文明 | 15 | ch08_safety | 0.900 | **0.967** | 0.867 | 0.811 |
| 九、应急预案 | 12 | ch09_emergency | **0.750** | 0.694 | 0.528 | 0.444 |
| 十、绿色施工 | 5 | ch10_green | **0.900** | 0.867 | 0.600 | 0.600 |

---

## 二、Reranker 综合排名

基于 Qwen3-Embedding-0.6B 的 top-10 候选进行二次排序。

| # | Reranker | 类型 | Rerank MRR@3 | Hit@1 | Hit@3 | MRR增益 | 延迟(ms) | 显存(MB) |
|---|---------|------|-------------|-------|-------|--------|---------|---------|
| 1 | Qwen3-Reranker-4B | CausalLM | **0.8933** | 86.0% | 93.0% | **+0.0333** | 294.1 | 11295 |
| 2 | Qwen3-Reranker-8B | CausalLM | 0.8883 | 86.0% | 93.0% | +0.0283 | 471.0 | 19213 |
| 3 | Qwen3-Reranker-0.6B | CausalLM | 0.8683 | 82.0% | 92.0% | +0.0083 | 127.5 | 4426 |
| 4 | bge-reranker-v2-m3 | CrossEncoder | 0.7867 | 75.0% | 83.0% | -0.0733 | 35.5 | 4336 |

**关键发现**：
- Qwen3-Reranker-4B 增益最大（+0.033），特别在长文本和弱章节上提升显著
- bge-reranker-v2-m3 产生负增益，领域适配性差
- Qwen3 Reranker 使用 CausalLM 架构（yes/no token 概率打分），非标准 CrossEncoder

### Reranker 按章节 MRR@3 对比

| 章节 | Qwen3-RR-4B | Qwen3-RR-0.6B | bge-reranker | 原始(0.6B) |
|------|-------------|---------------|-------------|-----------|
| 一、编制依据 | 0.800 | **1.000** | 0.800 | 0.900 |
| 二、工程概况 | **0.833** | **1.000** | 0.667 | 0.833 |
| 三、施工组织 | **0.667** | **0.667** | 0.667 | 0.667 |
| 四、施工安排 | **0.750** | 0.625 | **0.750** | 0.750 |
| 五、施工准备 | **1.000** | **1.000** | **1.000** | 1.000 |
| 六、施工方法 | **0.928** | 0.917 | 0.817 | 0.861 |
| 七、质量管理 | **0.867** | 0.789 | 0.700 | 0.867 |
| 八、安全文明 | **0.967** | 0.933 | 0.867 | 0.967 |
| 九、应急预案 | **0.792** | 0.708 | 0.639 | 0.694 |
| 十、绿色施工 | **1.000** | 0.900 | 0.800 | 0.867 |

**4B vs 0.6B 关键差异**：
- 应急预案 +0.084，绿色施工 +0.100，质量管理 +0.078
- 编制依据 -0.200（0.6B 反而更优，小样本波动）

### Reranker 按片段长度 MRR@3

| 片段长度 | Qwen3-RR-4B | Qwen3-RR-0.6B | bge-reranker | 原始(0.6B) |
|---------|-------------|---------------|-------------|-----------|
| <512 | 0.940 | **0.949** | 0.821 | 0.937 |
| 512-1024 | **0.861** | 0.778 | **0.833** | 0.741 |
| >1024 | **0.692** | 0.564 | 0.538 | 0.615 |

**4B Reranker 在长文本上优势明显**：>1024 字片段 MRR@3 从 0.564 提升至 0.692（+22.7%）。

---

## 三、联合管道最优组合（E2E）

Top-2 嵌入模型 × Top-2 Reranker = 4 组组合。

| # | Embedding | Reranker | E2E MRR@3 | Hit@1 | Hit@3 | 延迟(ms) | 组合显存(MB) | 可部署 |
|---|-----------|---------|-----------|-------|-------|---------|-------------|--------|
| 1 | Qwen3-Embedding-4B | Qwen3-Reranker-4B | **0.9067** | **87.0%** | **95.0%** | 409.8 | 15450 | ✅ |
| 2 | Qwen3-Embedding-0.6B | Qwen3-Reranker-4B | **0.8933** | 86.0% | 93.0% | 354.9 | 8871 | ✅ |
| 3 | Qwen3-Embedding-4B | Qwen3-Reranker-0.6B | 0.8683 | 81.0% | 93.0% | 219.6 | 8871 | ✅ |
| 4 | Qwen3-Embedding-0.6B | Qwen3-Reranker-0.6B | 0.8683 | 82.0% | 92.0% | 168.9 | 2283 | ✅ |

---

## 四、选型决策

### 推荐部署组合（三档可选）

| 档位 | 组合 | E2E MRR@3 | 显存 | 延迟 | 适用场景 |
|------|------|-----------|------|------|---------|
| **高精度** | 4B Emb + 4B RR | 0.9067 | 15.5GB | 410ms | 离线批量审核，精度优先 |
| **均衡（推荐）** | 0.6B Emb + 4B RR | 0.8933 | 8.9GB | 355ms | 生产部署，精度/资源平衡 |
| **轻量** | 0.6B Emb + 0.6B RR | 0.8683 | 2.3GB | 169ms | LLM 共享 GPU，响应优先 |

### 决策分析

**推荐组合：Qwen3-Embedding-0.6B + Qwen3-Reranker-4B（均衡档）**

| 指标 | 值 | 说明 |
|------|-----|------|
| E2E MRR@3 | 0.8933 | 仅比最高精度低 1.3% |
| E2E Hit@1 | 86.0% | 86% 的查询首条即命中 |
| E2E Hit@3 | 93.0% | 93% 的查询前三条命中 |
| 组合显存 | 8,871 MB | 剩余 15.1GB 可加载 LLM |
| 端到端延迟 | 354.9 ms | 单次检索亚秒响应 |
| Embedding 维度 | 1024 | 与 sqlite-vec 兼容 |

**理由**：
1. 比轻量档高 2.5% MRR@3（0.893 vs 0.868），Hit@1 高 4%（86% vs 82%）
2. 比高精度档省 6.6GB 显存，延迟快 55ms，但 MRR@3 仅低 1.3%
3. 8.9GB 显存可与 Qwen2.5-14B-GPTQ-Int4（~10GB）共享 24GB GPU
4. 4B Reranker 在长文本（>1024 字）和弱章节（应急预案）上优势显著

### 配置参数

```python
# qmd 嵌入配置
EMBEDDING_CONFIG = {
    "model_name": "Qwen/Qwen3-Embedding-0.6B",
    "embedding_dim": 1024,
    "max_seq_length": 32768,
    "batch_size": 2,           # 长文本 OOM 防护
    "torch_dtype": "float16",
    "padding_side": "left",
    "encode_kwargs": {"prompt_name": "query"},
}

# Reranker 配置
RERANKER_CONFIG = {
    "model_name": "Qwen/Qwen3-Reranker-4B",
    "type": "qwen3_causal",    # CausalLM 架构，非 CrossEncoder
    "max_length": 8192,
    "torch_dtype": "float16",
    "top_k_rerank": 10,        # 从 Embedding top-10 中 rerank
    "final_top_k": 3,          # 最终返回 top-3
}

# 检索参数
RETRIEVAL_CONFIG = {
    "top_k_embedding": 10,
    "top_k_rerank": 3,
    "similarity_threshold": 0.6,
}
```

---

## 五、8 Collection 检索策略建议

基于 Qwen3-Reranker-4B 的按章节评测数据：

| Collection | 对应章节 | Emb MRR@3 | RR-4B MRR@3 | 推荐策略 | 依据 |
|-----------|---------|-----------|-------------|---------|------|
| ch01_basis | 编制依据 | 0.900 | 0.800 | 仅 Embedding | Rerank 有负增益(-0.10)，片段短且明确 |
| ch06_methods | 施工方法 | 0.861 | 0.928 | Emb + Rerank | 核心章节(30条)，Rerank 提升 +0.067 |
| ch07_quality | 质量管理 | 0.867 | 0.867 | Emb + Rerank（可选） | Rerank 持平，可视延迟预算决定 |
| ch08_safety | 安全文明 | 0.967 | 0.967 | 仅 Embedding | 已极高精度，Rerank 无增益 |
| ch09_emergency | 应急预案 | 0.694 | 0.792 | **Emb + Rerank + metadata** | 最薄弱章节，4B Rerank 提升最大(+0.098) |
| ch10_green | 绿色施工 | 0.867 | 1.000 | Emb + Rerank | Rerank 提升至满分 |
| equipment | 施工准备 | 1.000 | 1.000 | 仅 Embedding | 满分检索，无需 Rerank |
| templates | 组织/安排 | 0.667-1.0 | 0.667-0.75 | Emb + metadata | 模板片段按章节过滤即可 |

### 优化建议

1. **ch09_emergency**：增加 `engineering_type` 和 `accident_type` 元数据过滤
2. **长文本策略**：>1024 字片段生成 summary embedding 作为补充索引
3. **按需 Rerank**：ch01/ch05/ch08 跳过 Rerank 以节省延迟

---

## 六、补充评测模型

| 模型 | MRR@3 | 显存(MB) | 延迟(ms) | 结论 |
|------|-------|---------|---------|------|
| Qwen3-Embedding-8B | OOM | >16GB | — | 无法在 24GB GPU 上评测 |
| Qwen3-Reranker-8B | 0.8883 | 19213 | 471 | **不如 4B**（0.893），不推荐 |

**Reranker 参数规模与精度的关系**：0.6B(0.868) < 4B(0.893) > 8B(0.888)，4B 为最优点。

---

## 七、qmd 集成验证

验证脚本 `scripts/verify_qmd_integration.py` 结果：6/6 通过

| 验证项 | 状态 | 说明 |
|--------|------|------|
| SentenceTransformerBackend 加载 | ✅ | 维度=1024 |
| embed()/embed_batch() | ✅ | 单条+批量均正确 |
| sqlite-vec 存储+检索 | ✅ | 索引→嵌入→检索全流程 |
| 端到端检索准确性 | ✅ | 3/3 正确 (100%) |
| Reranker CausalLM 加载+打分 | ✅ | yes=0.999 > no=0.000 |
| 显存预算 (<24GB) | ✅ | Emb+RR=2273MB |

> ⚠️ qmd 当前 `rerank()` 使用余弦相似度，需实现 `Qwen3CausalLMBackend` 以集成 4B Reranker

---

## 附录：评测方法说明

- **MRR@K**：Mean Reciprocal Rank，正确结果在 top-K 中的排名倒数均值
- **Hit@K**：正确结果出现在 top-K 中的比例
- **区分度**：正确片段与最高错误片段的 cosine 分数差均值
- **Reranker 评测**：基于 Qwen3-Embedding-0.6B 的 top-10 候选进行二次排序
- **E2E 管道**：Embedding top-10 → Reranker 重排 → top-3 计算 MRR@3
- **Hard Negatives**：4 种类型 — 同章不同工程、不同章同工程、同章同工程、随机
- **Qwen3 Reranker 打分**：CausalLM 生成 yes/no token 的 log_softmax 概率
